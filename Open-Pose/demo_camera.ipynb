{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "usage: ipykernel_launcher.py [-h] [--device DEVICE] [--model MODEL]\n",
      "                             [--frame_ratio FRAME_RATIO]\n",
      "                             [--process_speed PROCESS_SPEED]\n",
      "                             [--out_name OUT_NAME] [--mirror MIRROR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\DELL\\AppData\\Roaming\\jupyter\\runtime\\kernel-ac9566cf-8c38-41b1-9d8e-70cf2d9dcc79.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import time\n",
    "from config_reader import config_reader\n",
    "\n",
    "from processing import extract_parts, draw\n",
    "\n",
    "from model.cmu_model import get_testing_model\n",
    "\n",
    "\n",
    "os.path.abspath(os.path.dirname(sys.argv[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "\n",
    "currentDT = time.localtime()\n",
    "start_datetime = time.strftime(\"-%m-%d-%H-%M-%S\", currentDT)\n",
    "\n",
    "\n",
    "def crop(image, w, f):\n",
    "    return image[:, int(w * f): int(w * (1 - f))]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--device', type=int, default=0, help='ID of the device to open')\n",
    "    parser.add_argument('--model', type=str, default='model/keras/model.h5', help='path to the weights file')\n",
    "    parser.add_argument('--frame_ratio', type=int, default=7, help='analyze every [n] frames')\n",
    "    # --process_speed changes at how many times the model analyzes each frame at a different scale\n",
    "    parser.add_argument('--process_speed', type=int, default=1,\n",
    "                        help='Int 1 (fastest, lowest quality) to 4 (slowest, highest quality)')\n",
    "    parser.add_argument('--out_name', type=str, default=None, help='name of the output file to write')\n",
    "    parser.add_argument('--mirror', type=bool, default=True, help='whether to mirror the camera')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    device = args.device\n",
    "    keras_weights_file = args.model\n",
    "    frame_rate_ratio = args.frame_ratio\n",
    "    process_speed = args.process_speed\n",
    "    out_name = args.out_name\n",
    "    mirror = args.mirror\n",
    "\n",
    "    print('start processing...')\n",
    "\n",
    "    # load model\n",
    "    # authors of original model don't use\n",
    "    # vgg normalization (subtracting mean) on input images\n",
    "    model = get_testing_model()\n",
    "    model.load_weights(keras_weights_file)\n",
    "\n",
    "    # load config\n",
    "    params, model_params = config_reader()\n",
    "\n",
    "    # Video reader\n",
    "    cam = cv2.VideoCapture(device)\n",
    "    # CV_CAP_PROP_FPS\n",
    "    input_fps = cam.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"Running at {} fps.\".format(input_fps))\n",
    "\n",
    "    ret_val, orig_image = cam.read()\n",
    "\n",
    "    width = orig_image.shape[1]\n",
    "    height = orig_image.shape[0]\n",
    "    factor = 0.3\n",
    "\n",
    "    out = None\n",
    "    # Output location\n",
    "    if out_name is not None and ret_val is not None:\n",
    "        output_path = 'videos/outputs/'\n",
    "        output_format = '.mp4'\n",
    "        video_output = output_path + out_name + output_format\n",
    "\n",
    "        # Video writer\n",
    "        output_fps = input_fps / frame_rate_ratio\n",
    "\n",
    "        tmp = crop(orig_image, width, factor)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(video_output, fourcc, output_fps, (tmp.shape[1], tmp.shape[0]))\n",
    "\n",
    "        del tmp\n",
    "\n",
    "    scale_search = [0.22, 0.25, .5, 1, 1.5, 2]  # [.5, 1, 1.5, 2]\n",
    "    scale_search = scale_search[0:process_speed]\n",
    "\n",
    "    params['scale_search'] = scale_search\n",
    "\n",
    "    i = 0  # default is 0\n",
    "    resize_fac = 8\n",
    "    # while(cam.isOpened()) and ret_val is True:\n",
    "    while True:\n",
    "\n",
    "        cv2.waitKey(10)\n",
    "\n",
    "        if cam.isOpened() is False or ret_val is False:\n",
    "            break\n",
    "\n",
    "        if mirror:\n",
    "            orig_image = cv2.flip(orig_image, 1)\n",
    "\n",
    "        tic = time.time()\n",
    "\n",
    "        cropped = crop(orig_image, width, factor)\n",
    "\n",
    "        input_image = cv2.resize(cropped, (0, 0), fx=1/resize_fac, fy=1/resize_fac, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # generate image with body parts\n",
    "        all_peaks, subset, candidate = extract_parts(input_image, params, model, model_params)\n",
    "        canvas = draw(cropped, all_peaks, subset, candidate, resize_fac=resize_fac)\n",
    "\n",
    "        print('Processing frame: ', i)\n",
    "        toc = time.time()\n",
    "        print('processing time is %.5f' % (toc - tic))\n",
    "\n",
    "        if out is not None:\n",
    "            out.write(canvas)\n",
    "\n",
    "        # canvas = cv2.resize(canvas, (0, 0), fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        cv2.imshow('frame', canvas)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        ret_val, orig_image = cam.read()\n",
    "\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
